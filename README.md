### lucene4.6.0笔记

> 数据目录

> 索引目录

#### 读写流程
1. 写入流程（创建一个文档、创建IndexWriter、开始索引过程）


    1. 创建一个方法来获取从数据目录文本文件中获得 Lucene 的文档。
    2. 创建各种类型的是含有键作为名称和值作为内容被编入索引键值对字段。
        field，
    3. 设置字段中进行分析或不设置。在我们的实例中，只有内容被分析，因为它可能包含数据，诸如 a, am, are, an，它不要求在搜索操作等等。
        analyzer，源字符串首先经过analyzer处理，包括：分词，分成一个个单词；去除stopword（可选）。
    4. 新创建的字段添加到文档对象并返回给调用者的方法。
        document,将源中需要的信息加入Document的各个Field中，并把需要索引的Field索引起来，把需要存储的Field存储起来。
    5. 创建一个 IndexWriter 对象，创建其应指向位置，其中索引是存储一个lucene的目录，初始化索引目录
    5. 将索引写入存储器，存储器可以是内存或磁盘。
        
    
2. 读出流程


    1. 用户提供搜索关键词，经过analyzer处理。
    2. 对处理后的关键词搜索索引找出对应的Document。
    3. 用户根据需要从找到的Document中提取需要的Field。
    
#### 索引类
* Directory,表示索引的存储位置，并通常是文件的列表。这些文件被称为索引文件。索引文件通常创建一次，然后用于读操作或可以被删除。

* IndexWriter，

* Analyzer，是分词器，目的只有一个：按语义划分
    * 分词
    * 停止词
   
* Document，用是户提供的源是一条条记录，它们可以是文本文件、字符串或者数据库表的一条记录等等

* Field，一个Document可以包含多个信息域，例如一篇文章可以包含“标题”、“正文”、“最后修改时间”等信息域
    * 存储
    * 索引
        
* Token，token是term的一次出现，它包含term文本和相应的起止偏移，以及一个类型字符串。
  一句话中可以出现多次相同的词语，它们都用同一个term表示，但是用不同的token，每个token标记该词语出现的地方。

* Segment，添加索引时并不是每个document都马上添加到同一个索引文件，
  它们首先被写入到不同的小文件，然后再合并成一个大索引文件，
  这里每个小文件都是一个segment。

#### 搜索类
* IndexSearcher，

* Term，是搜索的最小单位，它表示文档的一个词语，term由两部分组成：
    * 它表示的词语
    * 这个词语所出现的field名字

* Query,是一个抽象类，包含各种实用方法，所有类型查询的父在Lucene的搜索过程中使用
    * TermQuery，是最常用的查询对象，并且是许多复杂的查询，是lucene可利用的基础

* TopDocs,指向相匹配的搜索条件的前N个搜索结果。
    * TopFieldDocs





#### 索引
1. 索引格式
    1. 一种是除配置文件外，每一个Document独立成为一个文件（这种搜索起来会影响速度）。
    2. 另一种是全部的Document成一个文件，这样属于复合模式就快了

2. 索引文件可放的位置
    1. 硬盘，可以用FSDirectory()
    2. 内存，用RAMDirectory()

3. 索引的合并
    
4. 索引的操作
    1. addDocument创建索引，新的可用内容
    2. updateDocument重新创建索引，以反映变化的内容
    3. deleteDocument删除索引,以排除它们不需要被索引的文档/搜索
    4. field字段选项,指定的方式或控制的方式，一个字段的内容进行搜索
        
        
        Index.ANALYZED - 先分析然后做索引。用于普通的文本索引。分析仪将打断该字段的值转换成标记流，每个令牌是搜索分开。
        Index.NOT_ANALYZED - 不分析，但这样做索引。用于完整的文本索引，例如人的名字，URL等。
        Index.ANALYZED_NO_NORMS - 变式Index.ANALYZED。分析仪将打破该字段的值转换成标记流，每个令牌是搜索分开，
                                  但规范是不存储在indexes.NORMS被用来提高搜索但有时内存消耗。
        Index.Index.NOT_ANALYZED_NO_NORMS - 变式Index.NOT_ANALYZED。索引是这样做，但规范NORMS是不存储在索引。
        Index.NO - 字段值不搜索。
    
#### lucene的高级搜索
1. 排序（Lucene有内置的排序用IndexSearcher.search(query,sort)但是功能并不理想）
2. 多域搜索MultiFieldQueryParser

#### 参考
1. lucene的索引不能太大，要不然效率会很低。大于1G的时候就必须考虑分布索引的问题
2. 不建议用多线程来建索引，产生的互锁问题很麻烦。经常发现索引被lock，无法重新建立的情况
3. 中文分词是个大问题，目前免费的分词效果都很差。如果有能力还是自己实现一个分词模块，用最短路径的切分方法，网上有教材和demo源码，可以参考。
4. 建增量索引的时候很耗cpu，在访问量大的时候会导致cpu的idle为0
5. 默认的评分机制不太合理，需要根据自己的业务定制
